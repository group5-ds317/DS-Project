{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"jUGP-RwaRfAL"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import math"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L3i2ULsGRqlh"},"outputs":[],"source":["from sklearn.preprocessing import normalize\n","from sklearn.metrics.pairwise import cosine_similarity\n","from sklearn.feature_extraction.text import TfidfVectorizer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2138,"status":"ok","timestamp":1733470877801,"user":{"displayName":"0390_ Phan Thanh Hải","userId":"13609693981152396951"},"user_tz":-420},"id":"z7eV7OJoRxf3","outputId":"cb04c977-6460-4225-dfe4-c72d1e72536b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gxXiTTTpRzLj"},"outputs":[],"source":["processed_student = pd.read_excel('/content/drive/MyDrive/Nhóm 5 - DS317.P11/Đồ án mô học/Dataset/Processed/Processed Data With Raw Data/processed_student.xlsx', index_col=0)\n","processed_course = pd.read_excel('/content/drive/MyDrive/Nhóm 5 - DS317.P11/Đồ án mô học/Dataset/Processed/Processed Data With Raw Data/processed_course.xlsx', index_col=0)\n","processed_score = pd.read_excel('/content/drive/MyDrive/Nhóm 5 - DS317.P11/Đồ án mô học/Dataset/Processed/Processed Data With Raw Data/processed_score.xlsx', index_col=0)\n","subject_popularity = pd.read_excel('/content/drive/MyDrive/Nhóm 5 - DS317.P11/Đồ án mô học/Dataset/Processed/Processed Data With Raw Data/subject_popularity.xlsx', index_col = 0)\n","group_sum_course = pd.read_excel('/content/drive/MyDrive/Nhóm 5 - DS317.P11/Đồ án mô học/Dataset/Processed/Processed Data With Raw Data/group_sum_course.xlsx')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DWnuSjGkT9Lj"},"outputs":[],"source":["class Baseline1():\n","    def __init__(self, student_df, score_df, course_df, subject_popularity_df, group_sum_course):\n","        self.student = student_df\n","        self.score = score_df\n","        self.course = course_df\n","        self.subject = subject_popularity_df\n","        self.group_sum_course = group_sum_course\n","\n","    def get_group_sum_course(self, faculty: str, year: int, term: int) -> pd.DataFrame:\n","      group_course_result = self.group_sum_course.loc[(self.group_sum_course['khoa'] == faculty) & (self.group_sum_course['namhoc'] < year) & (self.group_sum_course['sohocky'] == term - 1), :]\n","      group_course_result = group_course_result[['khoa', 'somonhoc']]\n","      group_course_result = group_course_result.groupby('khoa').mean()\n","      group_course_result['somonhoc'] = group_course_result['somonhoc'].apply(lambda x: math.ceil(x))\n","      group_course_result = group_course_result.reset_index()\n","      return group_course_result.iloc[0]['somonhoc']\n","\n","    def get_subject_popularity(self, mssv: str, top_m: int, current_term: int, attended_courses: list[str]) -> np.array:\n","        student_info = self.student[self.student['mssv'] == mssv].iloc[0]\n","        faculty = student_info['khoa']\n","        start_year = student_info['namhoc_batdau']\n","\n","        target_year = start_year + (current_term - 1) // 2\n","        target_term = (current_term - 1) % 2 + 1\n","        faculty_courses = self.subject[self.subject['khoa'] == faculty]\n","        previous_courses = faculty_courses[\n","            (faculty_courses['namhoc'] < target_year) |\n","            ((faculty_courses['namhoc'] == target_year) & (faculty_courses['sohocky'] < target_term))\n","        ]\n","        previous_courses = previous_courses.sort_values(by=['dophobien_scaled'], ascending=False)\n","        previous_courses = previous_courses.drop_duplicates(subset=['mamh'], keep='first')\n","        previous_courses = previous_courses[~previous_courses['mamh'].isin(attended_courses)]\n","        top_courses = previous_courses.nlargest(top_m, 'sosv')['mamh']\n","        return top_courses.values\n","\n","    def get_failed_courses(self, mssv: str, term: int) -> np.array:\n","        failed_courses = self.score[\n","            (self.score['mssv'] == mssv) &\n","            (self.score['diem'] < 5) &\n","            (self.score['sohocky'] == term - 1)\n","        ]['mamh'].unique()\n","        return failed_courses\n","\n","    def get_attended_courses(self, mssv: str, term: int) -> np.array:\n","        attended_courses = self.score[\n","            (self.score['mssv'] == mssv) &\n","            (self.score['sohocky'] == term - 1)\n","        ]['mamh'].unique()\n","        return attended_courses\n","\n","    def get_all_attended_courses(self, mssv: str, term: int) -> np.array:\n","        attended_courses = self.score[\n","            (self.score['mssv'] == mssv) &\n","            (self.score['sohocky'] < term)\n","        ]['mamh'].unique()\n","        return attended_courses\n","\n","    def combined_feature(self, courses: np.array) -> list:\n","        course_texts = self.course[self.course['mamh'].isin(courses)].apply(\n","            lambda row: f\"{row['mamh']} {row['nganhmh']} {row['loaimh']} {row['nhomloaimh']}\", axis=1\n","        ).tolist()\n","        return course_texts\n","\n","    def aggregate_cosine_sim(self, cosine_sim_matrix: pd.DataFrame, type: str) -> pd.DataFrame:\n","      if type == 'max':\n","        return cosine_sim_matrix.max(axis=1)\n","      elif type == 'min':\n","        return cosine_sim_matrix.min(axis=1)\n","      elif type == 'mean':\n","        return cosine_sim_matrix.mean(axis=1)\n","      elif type == 'sum':\n","        return cosine_sim_matrix.sum(axis=1)\n","\n","    def recommend(self, mssv: str, term: int, pooling: str, top_m: int) -> pd.DataFrame:\n","        faculty = self.student[self.student['mssv'] == mssv]['khoa'].values[0]\n","        faculty = faculty.strip()\n","        year = int(self.score[(self.score['mssv'] == mssv) & (self.score['sohocky'] == term)]['namhoc'].values[0])\n","\n","        all_attended_courses = self.get_all_attended_courses(mssv, term)\n","        attended_courses = self.get_attended_courses(mssv, term)\n","        failed_courses = self.get_failed_courses(mssv, term)\n","\n","        popular_courses = self.get_subject_popularity(mssv, top_m, term, all_attended_courses)\n","\n","        recommended_courses = np.setdiff1d(popular_courses, all_attended_courses)\n","        recommended_courses = np.unique(np.concatenate((recommended_courses, failed_courses)))\n","\n","        all_courses = np.concatenate((attended_courses, recommended_courses))\n","        course_texts = self.combined_feature(all_courses)\n","\n","        vectorizer = TfidfVectorizer()\n","        vectorizer.fit(course_texts)\n","\n","        attended_vectors = vectorizer.transform(self.combined_feature(attended_courses))\n","        recommended_vectors = vectorizer.transform(self.combined_feature(recommended_courses))\n","\n","        cosine_sim_matrix = cosine_similarity(recommended_vectors, attended_vectors)\n","        cosine_sim_matrix_df = pd.DataFrame(cosine_sim_matrix, index=recommended_courses, columns=attended_courses)\n","\n","        top_n = self.get_group_sum_course(faculty, year, term)\n","        top_recommended = self.aggregate_cosine_sim(cosine_sim_matrix_df, pooling).nlargest(int(top_n))\n","\n","        return top_recommended.reset_index().rename(columns={'index': 'mamh', 0: 'similarity_score'})\n","\n","    def evaluate(self, mssv: str, term: int, pooling: str, top_m: int) -> float:\n","        recommended_courses = self.recommend(mssv, term, pooling, top_m)['mamh']\n","        actual_courses = self.score[(self.score['mssv'] == mssv) & (self.score['sohocky'] == term)]['mamh'].unique()\n","\n","        true_positive_count = recommended_courses.isin(actual_courses).sum()\n","        precision = true_positive_count / len(recommended_courses) if len(recommended_courses) > 0 else 0\n","        recall = true_positive_count / len(actual_courses) if len(actual_courses) > 0 else 0\n","        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n","\n","        return precision, recall, f1_score\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b9EK4g8-z71V","outputId":"3324c9d8-87e6-44b2-fbbc-92234e15a664","executionInfo":{"status":"ok","timestamp":1733479177210,"user_tz":-420,"elapsed":4021961,"user":{"displayName":"0390_ Phan Thanh Hải","userId":"13609693981152396951"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 4/4 [2:17:23<00:00, 2060.82s/it]\n"]}],"source":["import random\n","from tqdm import tqdm\n","\n","# random.seed(42)\n","# Lọc các sinh viên bắt đầu học năm 2014\n","student_2014 = processed_student[processed_student['namhoc_batdau'] == 2014]['mssv'].unique()\n","\n","terms = [2, 3, 4, 5]\n","filtered_scores = processed_score[processed_score['sohocky'].isin(terms) & processed_score['mssv'].isin(student_2014)]\n","\n","student_with_all_terms = filtered_scores.groupby('mssv').filter(lambda x: set(x['sohocky']) == set(terms))['mssv'].unique()\n","\n","student_with_all_terms = list(student_with_all_terms)\n","\n","\n","qualified_students = list(set(student_2014) & set(student_with_all_terms))\n","# selected_students = random.sample(qualified_students, 100)\n","\n","gridsearch_results = []\n","for pooling in tqdm(['max', 'min', 'mean', 'sum']):\n","  for m in range(1, 21):\n","    evaluation_results = []\n","    for i in range(2, 6):\n","      for mssv in qualified_students:\n","          pipeline = Baseline1(processed_student, processed_score, processed_course, subject_popularity, group_sum_course)\n","          precision, recall, f1_score = pipeline.evaluate(mssv, i, pooling, m)\n","          evaluation_results.append({\n","              'mssv': mssv,\n","              'term': i,\n","              'precision': precision,\n","              'recall': recall,\n","              'f1_score': f1_score\n","          })\n","\n","    evaluation_df = pd.DataFrame(evaluation_results)\n","    mean_precision_by_term = evaluation_df.groupby('term')['precision'].mean()\n","    mean_precision = evaluation_df['precision'].mean()\n","    mean_recall_by_term = evaluation_df.groupby('term')['recall'].mean()\n","    mean_recall = evaluation_df['recall'].mean()\n","    mean_f1_score_by_term = evaluation_df.groupby('term')['f1_score'].mean()\n","    mean_f1_score = evaluation_df['f1_score'].mean()\n","    gridsearch_results.append({\n","        'pooling': pooling,\n","        'm': m,\n","        'mean_precision': mean_precision,\n","        'mean_recall': mean_recall,\n","        'mean_f1_score': mean_f1_score\n","    })\n","gridsearch_df = pd.DataFrame(gridsearch_results)\n","gridsearch_df.to_excel('/content/drive/MyDrive/Nhóm 5 - DS317.P11/Đồ án mô học/Gridsearch Finetune/Finetune With Raw Data/Baseline 1/gridsearch_results (full).xlsx')"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}