{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27513,"status":"ok","timestamp":1733470983429,"user":{"displayName":"0390_ Phan Thanh Hải","userId":"13609693981152396951"},"user_tz":-420},"id":"fsLVEpkvl11L","outputId":"41b80030-8054-4be3-d81e-93bb3d3b4a04"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5YNIKiHJ1GHC"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import math\n","from sklearn.preprocessing import normalize\n","from sklearn.metrics.pairwise import cosine_similarity\n","from sklearn.cluster import KMeans\n","from sklearn.feature_extraction.text import TfidfVectorizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1UqNqaq31UFl"},"outputs":[],"source":["processed_student = pd.read_excel('/content/drive/MyDrive/Nhóm 5 - DS317.P11/Đồ án mô học/Dataset/Processed/Processed Data With Raw Data/processed_student.xlsx', index_col=0)\n","processed_course = pd.read_excel('/content/drive/MyDrive/Nhóm 5 - DS317.P11/Đồ án mô học/Dataset/Processed/Processed Data With Raw Data/processed_course.xlsx', index_col=0)\n","processed_score = pd.read_excel('/content/drive/MyDrive/Nhóm 5 - DS317.P11/Đồ án mô học/Dataset/Processed/Processed Data With Raw Data/processed_score.xlsx', index_col=0)\n","group_sum_course = pd.read_excel('/content/drive/MyDrive/Nhóm 5 - DS317.P11/Đồ án mô học/Dataset/Processed/Processed Data With Raw Data/group_sum_course.xlsx')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KknjVT8GcDbW"},"outputs":[],"source":["class Baseline2():\n","    def __init__(self, student_df, score_df, course_df, group_sum_course , n_clusters=5):\n","        self.student = student_df\n","        self.score = score_df\n","        self.course = course_df\n","        self.group_sum_course = group_sum_course\n","        self.n_clusters = n_clusters\n","        self.gpa_credit_df = self.create_gpa_credit_df(self.student, self.score, self.course)\n","        self.cluster_students()\n","\n","    def get_group_sum_course(self, faculty: str, year: int, term: int) -> pd.DataFrame:\n","      group_course_result = self.group_sum_course.loc[(self.group_sum_course['khoa'] == faculty) & (self.group_sum_course['namhoc'] < year) & (self.group_sum_course['sohocky'] == term - 1), :]\n","      group_course_result = group_course_result[['khoa', 'somonhoc']]\n","      group_course_result = group_course_result.groupby('khoa').mean()\n","      group_course_result['somonhoc'] = group_course_result['somonhoc'].apply(lambda x: math.ceil(x))\n","      group_course_result = group_course_result.reset_index()\n","      return group_course_result.iloc[0]['somonhoc']\n","\n","    def create_gpa_credit_df(self, processed_student, processed_score, processed_course):\n","      \"\"\"\n","      Tạo DataFrame mới với 2 cột 'diemtrungbinh' và 'sotinchi' tính lũy.\n","\n","      Args:\n","          processed_student: DataFrame chứa thông tin sinh viên.\n","          processed_score: DataFrame chứa điểm số của sinh viên.\n","          processed_course: DataFrame chứa thông tin môn học.\n","\n","      Returns:\n","          DataFrame mới với 2 cột 'diemtrungbinh' và 'sotinchi' tính lũy.\n","      \"\"\"\n","\n","      # 1. Merge processed_score and processed_course to get 'sotc'\n","      merged_score = pd.merge(processed_score, processed_course[['mamh', 'sotc']], on='mamh', how='left')\n","\n","      # 2. Tính tổng số tín chỉ tích lũy cho mỗi sinh viên\n","      student_credits = merged_score.groupby('mssv')['sotc'].sum().reset_index()\n","      student_credits.rename(columns={'sotc': 'sotinchi'}, inplace=True)\n","\n","      # 3. Tính điểm trung bình tích lũy cho mỗi sinh viên\n","      # a. Tính điểm tích lũy (điểm * số tín chỉ) cho mỗi môn học\n","      merged_score['diemtichluy'] = merged_score['diem'] * merged_score['sotc']\n","\n","      # b. Tính tổng điểm tích lũy và tổng số tín chỉ cho mỗi sinh viên\n","      student_gpa = merged_score.groupby('mssv').agg({'diemtichluy': 'sum', 'sotc': 'sum'})\n","\n","      # c. Tính điểm trung bình tích lũy\n","      student_gpa['diemtrungbinh'] = student_gpa['diemtichluy'] / student_gpa['sotc']\n","      student_gpa = student_gpa.reset_index()[['mssv', 'diemtrungbinh']]\n","\n","      # 4. Ghép thông tin điểm trung bình và số tín chỉ tích lũy vào DataFrame sinh viên\n","      gpa_credit_df = pd.merge(processed_student[['mssv']], student_gpa, on='mssv', how='left')\n","      gpa_credit_df = pd.merge(gpa_credit_df, student_credits, on='mssv', how='left')\n","      return gpa_credit_df\n","\n","    # Phân cụm sinh viên\n","    def cluster_students(self):\n","        # Giả định 'gpa' và 'total_courses' là hai đặc trưng có trong student_df\n","        features = self.gpa_credit_df[['diemtrungbinh', 'sotinchi']]  # Đảm bảo có các đặc trưng này trong dữ liệu\n","        kmeans = KMeans(n_clusters=self.n_clusters, random_state=42)\n","        self.student['cluster'] = kmeans.fit_predict(features)\n","\n","    def get_cluster_students(self, mssv: str) -> np.array:\n","        cluster = self.student[self.student['mssv'] == mssv]['cluster'].values[0]\n","        cluster_students = self.student[self.student['cluster'] == cluster]['mssv'].values\n","        return cluster_students\n","\n","    def get_year(self, mssv: str, term: int) -> int:\n","      return int(self.score[(self.score['mssv'] == mssv) & (self.score['sohocky'] == term)]['namhoc'].values[0])\n","\n","    def get_cluster_courses(self, mssv: str, term: int) -> np.array:\n","        cluster_students = self.get_cluster_students(mssv)\n","        cluster_courses = self.score[\n","            (self.score['mssv'].isin(cluster_students)) &\n","            ((self.score['namhoc'] < self.get_year(mssv, term)) | ((self.score['namhoc'] == self.get_year(mssv, term)) & (self.score['sohocky'] < term)))\n","        ]['mamh'].unique()\n","        return cluster_courses\n","\n","    def get_failed_courses(self, mssv: str, term: int) -> np.array:\n","        failed_courses = self.score[\n","            (self.score['mssv'] == mssv) &\n","            (self.score['diem'] < 5) &\n","            (self.score['sohocky'] == term - 1)\n","        ]['mamh'].unique()\n","        return failed_courses\n","\n","    def get_attended_courses(self, mssv: str, term: int) -> np.array:\n","        attended_courses = self.score[\n","            (self.score['mssv'] == mssv) &\n","            (self.score['sohocky'] == term - 1)\n","        ]['mamh'].unique()\n","        return attended_courses\n","\n","    def get_all_attended_courses(self, mssv: str, term: int) -> np.array:\n","        attended_courses = self.score[\n","            (self.score['mssv'] == mssv) &\n","            (self.score['sohocky'] < term)\n","        ]['mamh'].unique()\n","        return attended_courses\n","\n","    def combined_feature(self, courses: np.array) -> list:\n","      course_texts = self.course[self.course['mamh'].isin(courses)].apply(\n","          lambda row: f\"{row['mamh']} {row['nganhmh']} {row['loaimh']} {row['nhomloaimh']}\", axis=1\n","      ).tolist()\n","      return course_texts\n","\n","    def aggregate_cosine_sim(self, cosine_sim_matrix: pd.DataFrame, type: str) -> pd.DataFrame:\n","      if type == 'max':\n","        return cosine_sim_matrix.max(axis=1)\n","      elif type == 'min':\n","        return cosine_sim_matrix.min(axis=1)\n","      elif type == 'mean':\n","        return cosine_sim_matrix.mean(axis=1)\n","      elif type == 'sum':\n","        return cosine_sim_matrix.sum(axis=1)\n","\n","    def recommend(self, mssv: str, term: int, pooling: str) -> pd.DataFrame:\n","        faculty = self.student[self.student['mssv'] == mssv]['khoa'].values[0]\n","        faculty = faculty.strip()\n","        year = int(self.score[(self.score['mssv'] == mssv) & (self.score['sohocky'] == term)]['namhoc'].values[0])\n","\n","        all_attended_courses = self.get_all_attended_courses(mssv, term)\n","        attended_courses = self.get_attended_courses(mssv, term)\n","        failed_courses = self.get_failed_courses(mssv, term)\n","\n","        cluster_courses = self.get_cluster_courses(mssv, term)\n","\n","        recommended_courses = np.setdiff1d(cluster_courses, all_attended_courses)\n","        recommended_courses = np.unique(np.concatenate((recommended_courses, failed_courses)))\n","\n","        all_courses = np.concatenate((attended_courses, recommended_courses))\n","        course_texts = self.combined_feature(all_courses)\n","\n","        vectorizer = TfidfVectorizer()\n","        vectorizer.fit(course_texts)\n","\n","        attended_vectors = vectorizer.transform(self.combined_feature(attended_courses))\n","        recommended_vectors = vectorizer.transform(self.combined_feature(recommended_courses))\n","\n","        cosine_sim_matrix = cosine_similarity(recommended_vectors, attended_vectors)\n","        cosine_sim_matrix_df = pd.DataFrame(cosine_sim_matrix, index=recommended_courses, columns=attended_courses)\n","\n","        top_n = self.get_group_sum_course(faculty, year, term)\n","        top_recommended = self.aggregate_cosine_sim(cosine_sim_matrix_df, pooling).nlargest(int(top_n))\n","\n","        return top_recommended.reset_index().rename(columns={'index': 'mamh', 0: 'similarity_score'})\n","\n","    def evaluate(self, mssv: str, term: int, pooling: str) -> float:\n","        recommended_courses = self.recommend(mssv, term, pooling)['mamh']\n","        actual_courses = self.score[(self.score['mssv'] == mssv) & (self.score['sohocky'] == term)]['mamh'].unique()\n","\n","        true_positive_count = recommended_courses.isin(actual_courses).sum()\n","        precision = true_positive_count / len(recommended_courses) if len(recommended_courses) > 0 else 0\n","        recall = true_positive_count / len(actual_courses) if len(actual_courses) > 0 else 0\n","        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n","\n","        return precision, recall, f1_score\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"fTh6I6np46sV","outputId":"b55044f5-785b-4502-e86d-e666a68b6d08"},"outputs":[{"name":"stdout","output_type":"stream","text":["505\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|█████     | 2/4 [3:37:11<3:37:12, 6516.27s/it]"]}],"source":["import random\n","from tqdm import tqdm\n","\n","# random.seed(42)\n","# Lọc các sinh viên bắt đầu học năm 2014\n","student_2014 = processed_student[processed_student['namhoc_batdau'] == 2014]['mssv'].unique()\n","\n","terms = [2, 3, 4, 5]\n","filtered_scores = processed_score[processed_score['sohocky'].isin(terms) & processed_score['mssv'].isin(student_2014)]\n","\n","student_with_all_terms = filtered_scores.groupby('mssv').filter(lambda x: set(x['sohocky']) == set(terms))['mssv'].unique()\n","\n","student_with_all_terms = list(student_with_all_terms)\n","\n","\n","qualified_students = list(set(student_2014) & set(student_with_all_terms))\n","print(len(qualified_students))\n","# selected_students = random.sample(qualified_students, 100)\n","\n","gridsearch_results = []\n","for pooling in tqdm(['max', 'min', 'mean', 'sum']):\n","  for k in range(2, 31):\n","    evaluation_results = []\n","    for i in range(2, 6):\n","      for mssv in qualified_students:\n","          pipeline = Baseline2(processed_student, processed_score, processed_course, group_sum_course, k)\n","          precision, recall, f1_score = pipeline.evaluate(mssv, i, pooling)\n","          evaluation_results.append({\n","              'mssv': mssv,\n","              'term': i,\n","              'precision': precision,\n","              'recall': recall,\n","              'f1_score': f1_score\n","          })\n","\n","    evaluation_df = pd.DataFrame(evaluation_results)\n","    mean_precision_by_term = evaluation_df.groupby('term')['precision'].mean()\n","    mean_precision = evaluation_df['precision'].mean()\n","    mean_recall_by_term = evaluation_df.groupby('term')['recall'].mean()\n","    mean_recall = evaluation_df['recall'].mean()\n","    mean_f1_score_by_term = evaluation_df.groupby('term')['f1_score'].mean()\n","    mean_f1_score = evaluation_df['f1_score'].mean()\n","    gridsearch_results.append({\n","        'pooling': pooling,\n","        'k': k,\n","        'mean_precision': mean_precision,\n","        'mean_recall': mean_recall,\n","        'mean_f1_score': mean_f1_score\n","    })\n","gridsearch_df = pd.DataFrame(gridsearch_results)\n","gridsearch_df.to_excel('/content/drive/MyDrive/Nhóm 5 - DS317.P11/Đồ án mô học/Gridsearch Finetune/Finetune With Raw Data/Baseline 2/gridsearch_results (full).xlsx')"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}