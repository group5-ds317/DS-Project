{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"kQg0AiwiskeT","executionInfo":{"status":"ok","timestamp":1733472868241,"user_tz":-420,"elapsed":779,"user":{"displayName":"0390_ Phan Thanh Hải","userId":"13609693981152396951"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import math"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"c0ULcX0xPb_L","executionInfo":{"status":"ok","timestamp":1733472873431,"user_tz":-420,"elapsed":5194,"user":{"displayName":"0390_ Phan Thanh Hải","userId":"13609693981152396951"}}},"outputs":[],"source":["from sklearn.preprocessing import normalize\n","from sklearn.metrics.pairwise import cosine_similarity"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19710,"status":"ok","timestamp":1733472893135,"user":{"displayName":"0390_ Phan Thanh Hải","userId":"13609693981152396951"},"user_tz":-420},"id":"4Qhxm1Ffssmi","outputId":"d8234146-3cf8-4daa-c183-9dbb0edecb3c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"GbipqCbksyAj","executionInfo":{"status":"ok","timestamp":1733472917272,"user_tz":-420,"elapsed":23820,"user":{"displayName":"0390_ Phan Thanh Hải","userId":"13609693981152396951"}}},"outputs":[],"source":["processed_student = pd.read_excel('/content/drive/MyDrive/Nhóm 5 - DS317.P11/Đồ án mô học/Dataset/Processed/Processed Data With Pre-Processed Data/processed_student.xlsx', index_col=0)\n","processed_score = pd.read_excel('/content/drive/MyDrive/Nhóm 5 - DS317.P11/Đồ án mô học/Dataset/Processed/Processed Data With Pre-Processed Data/processed_score.xlsx', index_col=0)\n","processed_course = pd.read_excel('/content/drive/MyDrive/Nhóm 5 - DS317.P11/Đồ án mô học/Dataset/Processed/Processed Data With Pre-Processed Data/processed_course.xlsx', index_col=0)\n","onehot_course = pd.read_excel('/content/drive/MyDrive/Nhóm 5 - DS317.P11/Đồ án mô học/Dataset/Processed/Processed Data With Pre-Processed Data/onehot_course.xlsx', index_col=0)\n","PhoBERT_paraphased_tomtat = pd.read_csv('/content/drive/MyDrive/Nhóm 5 - DS317.P11/Đồ án mô học/Dataset/Processed/Processed Data With Pre-Processed Data/PhoBERT_paraphased_tomtat.csv', index_col=0)\n","group_course = pd.read_excel('/content/drive/MyDrive/Nhóm 5 - DS317.P11/Đồ án mô học/Dataset/Processed/Processed Data With Pre-Processed Data/group_course.xlsx', index_col=0)\n","subject_score = pd.read_excel('/content/drive/MyDrive/Nhóm 5 - DS317.P11/Đồ án mô học/Dataset/Processed/Processed Data With Pre-Processed Data/subject_score.xlsx', index_col=0)\n","subject_popularity = pd.read_excel('/content/drive/MyDrive/Nhóm 5 - DS317.P11/Đồ án mô học/Dataset/Processed/Processed Data With Pre-Processed Data/subject_popularity.xlsx', index_col=0)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"cIPMRi9alf7w","executionInfo":{"status":"ok","timestamp":1733472917273,"user_tz":-420,"elapsed":8,"user":{"displayName":"0390_ Phan Thanh Hải","userId":"13609693981152396951"}}},"outputs":[],"source":["class Baseline4():\n","  def __init__(self, group_course, student_df, score_df, course_df, onehot_course_df, PhoBERT_paraphased_tomtat, subject_score_df, subject_popularity_df):\n","    self.group_course = group_course\n","    self.student = student_df\n","    self.score = score_df\n","    self.course = course_df\n","    self.onehot_course = onehot_course_df\n","    self.PhoBERT_paraphased_tomtat = PhoBERT_paraphased_tomtat\n","    self.subject_score = subject_score_df\n","    self.subject_popularity = subject_popularity_df\n","\n","  def get_falculty(self, mssv: str) -> str:\n","    return str(self.student[self.student['mssv'] == mssv].loc[:,'khoa'].values[0])\n","\n","  def get_year(self, mssv: str, term: int) -> int:\n","    return int(self.score[(self.score['mssv'] == mssv) & (self.score['sohocky'] == term)]['namhoc'].values[0])\n","\n","  def get_group_course(self, faculty: str, year: int, term: int) -> pd.DataFrame:\n","    group_course_result = self.group_course.loc[(self.group_course['khoa'] == faculty) & (self.group_course['namhoc'] < year) & (self.group_course['sohocky'] == term), :]\n","    group_course_result = group_course_result[['nhomloaimh', 'somonhoc']]\n","    group_course_result = group_course_result.groupby('nhomloaimh').mean()\n","    group_course_result['somonhoc'] = group_course_result['somonhoc'].apply(lambda x: math.ceil(x))\n","    return group_course_result.reset_index()\n","\n","  def get_passed_course(self, mssv: str, term: int, group_course: str) -> np.array:\n","    passed_course = self.score.loc[(self.score['mssv'] == mssv) & (self.score['sohocky'] == term) & (self.score['diem'] >= 5) & (self.score['nhomloaimh'] == group_course), :]\n","    return passed_course['mamh'].unique()\n","\n","  def get_failed_course(self, mssv: str, term: int, group_course: str) -> np.array:\n","    failed_course = self.score.loc[(self.score['mssv'] == mssv) & (self.score['sohocky'] == term) & (self.score['diem'] < 5) & (self.score['nhomloaimh'] == group_course), :]\n","    return failed_course['mamh'].unique()\n","\n","  def get_attended_course(self, mssv: str, term: int, group_course: str) -> np.array:\n","    failed_course = self.score.loc[(self.score['mssv'] == mssv) & (self.score['sohocky'] == term) & (self.score['nhomloaimh'] == group_course), :]\n","    return failed_course['mamh'].unique()\n","\n","  def get_all_course(self, year: int, term: int, group_course: str) -> np.array:\n","    all_course = self.score.loc[(self.score['nhomloaimh'] == group_course) & (self.score['namhoc'] <= year)] if term % 2 == 0 else self.score.loc[(self.score['nhomloaimh'] == group_course) & ((self.score['namhoc'] < year) | ((self.score['namhoc'] == year) & (self.score['hocky'] == 1)))]\n","    return all_course['mamh'].unique()\n","\n","  def get_all_attended_course(self, mssv: str, term: int, group_course: str) -> np.array:\n","    return self.score[(self.score['mssv'] == mssv) & (self.score['sohocky'] <= term) & (self.score['nhomloaimh'] == group_course)]['mamh'].unique()\n","\n","  def get_not_attended_course(self, mssv: str, year: int, term: int, group_course: str) -> np.array:\n","    all_course = self.get_all_course(year, term, group_course)\n","    all_attended_course = self.get_all_attended_course(mssv, term, group_course)\n","    return np.setdiff1d(all_course, all_attended_course)\n","\n","  def get_recommended_course(self, mssv: str, year: int, term: int, group_course: str) -> np.array:\n","    not_attended_course = self.get_not_attended_course(mssv, year, term, group_course)\n","    failed_course = self.get_failed_course(mssv, term, group_course)\n","    return np.unique(np.concatenate((not_attended_course, failed_course)))\n","\n","  def normalize_l2_features(self, features: pd.DataFrame) -> pd.DataFrame:\n","    return normalize(features, axis=0)\n","\n","  def vectorize_course(self, courses: np.array) -> pd.DataFrame:\n","    if len(courses) == 0:\n","      return pd.DataFrame()\n","\n","    filtered_data = self.course.loc[self.course['mamh'].isin(courses), :]\n","    filtered_data = pd.merge(filtered_data, self.onehot_course.drop(columns=['sotc']), on='mamh', how='left')\n","\n","    continuous_features = filtered_data[['mamh', 'sotc']].set_index('mamh')\n","    categorical_features = filtered_data[filtered_data.columns.drop(['sotc', 'nganhmh', 'loaimh', 'nhomloaimh'])].set_index('mamh')\n","    phobert_embedding_features = PhoBERT_paraphased_tomtat.loc[PhoBERT_paraphased_tomtat['mamh'].isin(courses), :].set_index('mamh')\n","\n","    continuous_features = self.normalize_l2_features(continuous_features)\n","    phobert_embedding_features = self.normalize_l2_features(phobert_embedding_features)\n","    features = np.concatenate((continuous_features, categorical_features, phobert_embedding_features), axis=1)\n","    return pd.DataFrame(features, index=filtered_data['mamh'])\n","\n","  def aggregate_cosine_sim(self, cosine_sim_matrix: pd.DataFrame, type: str) -> pd.DataFrame:\n","    if type == 'max':\n","      return cosine_sim_matrix.max(axis=1)\n","    elif type == 'min':\n","      return cosine_sim_matrix.min(axis=1)\n","    elif type == 'mean':\n","      return cosine_sim_matrix.mean(axis=1)\n","    elif type == 'sum':\n","      return cosine_sim_matrix.sum(axis=1)\n","\n","  def get_top_k(self, cosine_sim_aggregate: pd.DataFrame, k: int) -> pd.DataFrame:\n","    return cosine_sim_aggregate.nlargest(k)\n","\n","  def rerank(self, faculty, year, term, recommended_course):\n","    subject_scores_df = self.subject_score[(self.subject_score['mamh'].isin(recommended_course)) & ((self.subject_score['namhoc'] <= year) if term % 2 == 0 else ((self.subject_score['namhoc'] < year) | ((self.subject_score['namhoc'] == year) & (self.subject_score['sohocky'] % 2 != 0)))) & (self.subject_score['khoa'] == faculty)]\n","    # Get subject popularity for recommended courses\n","    subject_popularity_df = self.subject_popularity[(self.subject_popularity['mamh'].isin(recommended_course)) & ((self.subject_popularity['namhoc'] <= year) if term % 2 == 0 else ((self.subject_popularity['namhoc'] < year) | ((self.subject_popularity['namhoc'] == year) & (self.subject_popularity['sohocky'] % 2 != 0)))) & (self.subject_popularity['khoa'] == faculty)]\n","    merged_df = pd.merge(subject_scores_df[['mamh', 'dothanhtich_scaled']], subject_popularity_df[['mamh', 'dophobien_scaled']], on='mamh', how='inner')\n","\n","    # Calculate the combined score\n","    merged_df['combined_score'] = (merged_df['dothanhtich_scaled'] + merged_df['dophobien_scaled']) / 2\n","    merged_df = merged_df.sort_values(by=['combined_score'], ascending=False)\n","    merged_df = merged_df.drop_duplicates(subset=['mamh'], keep='first')\n","    return merged_df\n","\n","  def recommend(self, mssv: str, term: int, pooling: str, top_m: int) -> pd.DataFrame:\n","    faculty = self.get_falculty(mssv)\n","    faculty = faculty.strip()\n","    year = self.get_year(mssv, term)\n","    group_course = self.get_group_course(faculty, year, term)\n","    recommended_result = []\n","\n","    for group_course_index, group_course_row in group_course.iterrows():\n","      recommended_course = self.get_recommended_course(mssv, year, term-1, group_course_row['nhomloaimh'])\n","      recommended_features = self.vectorize_course(recommended_course)\n","      attended_course = self.get_attended_course(mssv, term-1, group_course_row['nhomloaimh'])\n","      attended_features = self.vectorize_course(attended_course)\n","      if len(attended_course) == 0 or len(recommended_features) == 0 :\n","        merged_df = self.rerank(faculty, year, term, recommended_course)\n","        top_k_df = merged_df.head(group_course_row['somonhoc'])\n","        recommended_result = recommended_result + [\n","            {\n","                'nhomloaimh': group_course_row['nhomloaimh'],\n","                'mamh': row['mamh'],\n","                'score': row['combined_score']\n","            }\n","            for _, row in top_k_df.iterrows()\n","        ]\n","      else:\n","        cosine_sim_matrix = cosine_similarity(recommended_features, attended_features)\n","        cosine_sim_matrix = pd.DataFrame(cosine_sim_matrix, index=recommended_features.index, columns=attended_features.index)\n","        cosine_max_aggregate = self.aggregate_cosine_sim(cosine_sim_matrix, pooling)\n","\n","        top_k_recommended_course = self.get_top_k(cosine_max_aggregate, top_m)\n","        merged_df = self.rerank(faculty, year, term, list(top_k_recommended_course.index))\n","        top_k_df = merged_df.head(group_course_row['somonhoc'])\n","        recommended_result = recommended_result + [\n","            {\n","                'nhomloaimh': group_course_row['nhomloaimh'],\n","                'mamh': row['mamh'],\n","                'score': row['combined_score']\n","            }\n","            for _, row in top_k_df.iterrows()\n","        ]\n","    return pd.DataFrame(recommended_result)\n","\n","  def evaluate(self, mssv: str, term: int, pooling: str, top_m: int) -> pd.DataFrame:\n","    recommended_courses = self.recommend(mssv, term, pooling, top_m)\n","    if len(recommended_courses) == 0:\n","      return 0, 0, 0\n","    recommended_courses = recommended_courses['mamh']\n","    actual_courses = self.score[(self.score['mssv'] == mssv) & (self.score['sohocky'] == term)]['mamh'].unique()\n","\n","    true_positive_count = recommended_courses.isin(actual_courses).sum()\n","    precision = true_positive_count / len(recommended_courses) if len(recommended_courses) > 0 else 0\n","    recall = true_positive_count / len(actual_courses) if len(actual_courses) > 0 else 0\n","    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n","\n","    return precision, recall, f1_score"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"UkaQnFR0fGCt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733476765739,"user_tz":-420,"elapsed":1611178,"user":{"displayName":"0390_ Phan Thanh Hải","userId":"13609693981152396951"}},"outputId":"53734b7a-eaed-415b-c1a4-3183859b886a"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 4/4 [1:04:07<00:00, 961.85s/it]\n"]}],"source":["import random\n","from tqdm import tqdm\n","\n","random.seed(42)\n","# Lọc các sinh viên bắt đầu học năm 2014\n","student_2014 = processed_student[processed_student['namhoc_batdau'] == 2014]['mssv'].unique()\n","\n","terms = [2, 3, 4, 5]\n","filtered_scores = processed_score[processed_score['sohocky'].isin(terms) & processed_score['mssv'].isin(student_2014)]\n","\n","student_with_all_terms = filtered_scores.groupby('mssv').filter(lambda x: set(x['sohocky']) == set(terms))['mssv'].unique()\n","\n","student_with_all_terms = list(student_with_all_terms)\n","\n","\n","qualified_students = list(set(student_2014) & set(student_with_all_terms))\n","selected_students = random.sample(qualified_students, 100)\n","\n","pooling_list = ['max', 'min', 'sum', 'mean']\n","gridsearch_results = []\n","for pooling in tqdm(pooling_list):\n","  for m in range(10, 21):\n","    evaluation_results = []\n","    for i in range(2, 6):\n","      for mssv in selected_students:\n","          pipeline = Baseline4(group_course, processed_student, processed_score, processed_course, onehot_course, PhoBERT_paraphased_tomtat, subject_score, subject_popularity)\n","          precision, recall, f1_score = pipeline.evaluate(mssv, i, pooling, m)\n","          evaluation_results.append({\n","              'mssv': mssv,\n","              'term': i,\n","              'precision': precision,\n","              'recall': recall,\n","              'f1_score': f1_score\n","          })\n","\n","    evaluation_df = pd.DataFrame(evaluation_results)\n","    mean_precision_by_term = evaluation_df.groupby('term')['precision'].mean()\n","    mean_precision = evaluation_df['precision'].mean()\n","    mean_recall_by_term = evaluation_df.groupby('term')['recall'].mean()\n","    mean_recall = evaluation_df['recall'].mean()\n","    mean_f1_score_by_term = evaluation_df.groupby('term')['f1_score'].mean()\n","    mean_f1_score = evaluation_df['f1_score'].mean()\n","    gridsearch_results.append({\n","        'pooling': pooling,\n","        'm': m,\n","        'mean_precision': mean_precision,\n","        'mean_recall': mean_recall,\n","        'mean_f1_score': mean_f1_score\n","    })\n","gridsearch_df = pd.DataFrame(gridsearch_results)\n","gridsearch_df.to_excel('/content/drive/MyDrive/Nhóm 5 - DS317.P11/Đồ án mô học/Gridsearch Finetune/Finetune With Pre-Processed Data/Baseline 4/gridsearch_results (full).xlsx')"]}],"metadata":{"colab":{"provenance":[{"file_id":"1SwUrRwp9cypx41V7zH08k8jUwSQkupDY","timestamp":1731138351578}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}