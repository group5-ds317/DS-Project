{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"kQg0AiwiskeT","executionInfo":{"status":"ok","timestamp":1733471101815,"user_tz":-420,"elapsed":1529,"user":{"displayName":"0390_ Phan Thanh Hải","userId":"13609693981152396951"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import math"]},{"cell_type":"code","source":["from sklearn.preprocessing import normalize\n","from sklearn.metrics.pairwise import cosine_similarity"],"metadata":{"id":"c0ULcX0xPb_L","executionInfo":{"status":"ok","timestamp":1733471113720,"user_tz":-420,"elapsed":2871,"user":{"displayName":"0390_ Phan Thanh Hải","userId":"13609693981152396951"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Qhxm1Ffssmi","executionInfo":{"status":"ok","timestamp":1733471136590,"user_tz":-420,"elapsed":21608,"user":{"displayName":"0390_ Phan Thanh Hải","userId":"13609693981152396951"}},"outputId":"be4f742c-bdf8-495b-9da3-4c14fef916fa"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["processed_student = pd.read_excel('/content/drive/MyDrive/Nhóm 5 - DS317.P11/Đồ án mô học/Dataset/Processed/Processed Data With Raw Data/processed_student.xlsx', index_col=0)\n","processed_score = pd.read_excel('/content/drive/MyDrive/Nhóm 5 - DS317.P11/Đồ án mô học/Dataset/Processed/Processed Data With Raw Data/processed_score.xlsx', index_col=0)\n","processed_course = pd.read_excel('/content/drive/MyDrive/Nhóm 5 - DS317.P11/Đồ án mô học/Dataset/Processed/Processed Data With Raw Data/processed_course.xlsx', index_col=0)\n","onehot_course = pd.read_excel('/content/drive/MyDrive/Nhóm 5 - DS317.P11/Đồ án mô học/Dataset/Processed/Processed Data With Raw Data/onehot_course.xlsx', index_col=0)\n","PhoBERT_paraphased_tomtat = pd.read_csv('/content/drive/MyDrive/Nhóm 5 - DS317.P11/Đồ án mô học/Dataset/Processed/Processed Data With Raw Data/PhoBERT_paraphased_tomtat.csv', index_col=0)\n","group_course = pd.read_excel('/content/drive/MyDrive/Nhóm 5 - DS317.P11/Đồ án mô học/Dataset/Processed/Processed Data With Raw Data/group_course.xlsx', index_col=0)"],"metadata":{"id":"GbipqCbksyAj","executionInfo":{"status":"ok","timestamp":1733471195260,"user_tz":-420,"elapsed":15277,"user":{"displayName":"0390_ Phan Thanh Hải","userId":"13609693981152396951"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["class Baseline3():\n","  def __init__(self, group_course, student_df, score_df, course_df, onehot_course_df, PhoBERT_paraphased_tomtat):\n","    self.group_course = group_course\n","    self.student = student_df\n","    self.score = score_df\n","    self.course = course_df\n","    self.onehot_course = onehot_course_df\n","    self.PhoBERT_paraphased_tomtat = PhoBERT_paraphased_tomtat\n","\n","  def get_falculty(self, mssv: str) -> str:\n","    return str(self.student[self.student['mssv'] == mssv].loc[:,'khoa'].values[0])\n","\n","  def get_year(self, mssv: str, term: int) -> int:\n","    return int(self.score[(self.score['mssv'] == mssv) & (self.score['sohocky'] == term)]['namhoc'].values[0])\n","\n","  def get_group_course(self, faculty: str, year: int, term: int) -> pd.DataFrame:\n","    group_course_result = self.group_course.loc[(self.group_course['khoa'] == faculty) & (self.group_course['namhoc'] < year) & (self.group_course['sohocky'] == term), :]\n","    group_course_result = group_course_result[['nhomloaimh', 'somonhoc']]\n","    group_course_result = group_course_result.groupby('nhomloaimh').mean()\n","    group_course_result['somonhoc'] = group_course_result['somonhoc'].apply(lambda x: math.ceil(x))\n","    return group_course_result.reset_index()\n","\n","  def get_passed_course(self, mssv: str, term: int, group_course: str) -> np.array:\n","    passed_course = self.score.loc[(self.score['mssv'] == mssv) & (self.score['sohocky'] == term) & (self.score['diem'] >= 5) & (self.score['nhomloaimh'] == group_course), :]\n","    return passed_course['mamh'].unique()\n","\n","  def get_failed_course(self, mssv: str, term: int, group_course: str) -> np.array:\n","    failed_course = self.score.loc[(self.score['mssv'] == mssv) & (self.score['sohocky'] == term) & (self.score['diem'] < 5) & (self.score['nhomloaimh'] == group_course), :]\n","    return failed_course['mamh'].unique()\n","\n","  def get_attended_course(self, mssv: str, term: int, group_course: str) -> np.array:\n","    attended_course = self.score.loc[(self.score['mssv'] == mssv) & (self.score['sohocky'] == term) & (self.score['nhomloaimh'] == group_course), :]\n","    return attended_course['mamh'].unique()\n","\n","  def get_all_course(self, group_course: str) -> np.array:\n","    all_course = self.course.loc[self.course['nhomloaimh'] == group_course]\n","    return all_course['mamh']\n","\n","  def get_all_attended_course(self, mssv: str, term: int, group_course: str) -> np.array:\n","    return self.score[(self.score['mssv'] == mssv) & (self.score['sohocky'] <= term) & (self.score['nhomloaimh'] == group_course)]['mamh'].unique()\n","\n","  def get_not_attended_course(self, mssv: str, term: int, group_course: str) -> np.array:\n","    all_course = self.get_all_course(group_course)\n","    all_attended_course = self.get_all_attended_course(mssv, term, group_course)\n","    return np.setdiff1d(all_course, all_attended_course)\n","\n","  def get_recommended_course(self, mssv: str, term: int, group_course: str) -> np.array:\n","    not_attended_course = self.get_not_attended_course(mssv, term, group_course)\n","    failed_course = self.get_failed_course(mssv, term, group_course)\n","    return np.unique(np.concatenate((not_attended_course, failed_course)))\n","\n","  def normalize_l2_features(self, features: pd.DataFrame) -> pd.DataFrame:\n","    return normalize(features, axis=0)\n","\n","  def vectorize_course(self, courses: np.array) -> pd.DataFrame:\n","    if len(courses) == 0:\n","      return pd.DataFrame()\n","\n","    filtered_data = self.course.loc[self.course['mamh'].isin(courses), :]\n","    filtered_data = pd.merge(filtered_data, self.onehot_course.drop(columns=['sotc']), on='mamh', how='left')\n","\n","    continuous_features = filtered_data[['mamh', 'sotc']].set_index('mamh')\n","    categorical_features = filtered_data[filtered_data.columns.drop(['sotc', 'nganhmh', 'loaimh', 'nhomloaimh'])].set_index('mamh')\n","    phobert_embedding_features = PhoBERT_paraphased_tomtat.loc[PhoBERT_paraphased_tomtat['mamh'].isin(courses), :].set_index('mamh')\n","\n","    continuous_features = self.normalize_l2_features(continuous_features)\n","    phobert_embedding_features = self.normalize_l2_features(phobert_embedding_features)\n","    features = np.concatenate((continuous_features, categorical_features, phobert_embedding_features), axis=1)\n","    return pd.DataFrame(features, index=filtered_data['mamh'])\n","\n","  def aggregate_cosine_sim(self, cosine_sim_matrix: pd.DataFrame, type: str) -> pd.DataFrame:\n","    if type == 'max':\n","      return cosine_sim_matrix.max(axis=1)\n","    elif type == 'min':\n","      return cosine_sim_matrix.min(axis=1)\n","    elif type == 'mean':\n","      return cosine_sim_matrix.mean(axis=1)\n","    elif type == 'sum':\n","      return cosine_sim_matrix.sum(axis=1)\n","\n","  def get_top_k(self, cosine_sim_aggregate: pd.DataFrame, k: int) -> pd.DataFrame:\n","    return cosine_sim_aggregate.nlargest(k)\n","\n","  def recommend(self, mssv: str, term: int, pooling='max') -> pd.DataFrame:\n","    faculty = self.get_falculty(mssv)\n","    faculty = faculty.strip()\n","    year = self.get_year(mssv, term)\n","    group_course = self.get_group_course(faculty, year, term)\n","    recommended_result = []\n","    for group_course_index, group_course_row in group_course.iterrows():\n","      recommended_course = self.get_recommended_course(mssv, term-1, group_course_row['nhomloaimh'])\n","      recommended_features = self.vectorize_course(recommended_course)\n","      attended_course = self.get_attended_course(mssv, term-1, group_course_row['nhomloaimh'])\n","      attended_features = self.vectorize_course(attended_course)\n","      if recommended_features.empty or attended_features.empty:\n","        continue\n","\n","      cosine_sim_matrix = cosine_similarity(recommended_features, attended_features)\n","      cosine_sim_matrix = pd.DataFrame(cosine_sim_matrix, index=recommended_features.index, columns=attended_features.index)\n","      cosine_max_aggregate = self.aggregate_cosine_sim(cosine_sim_matrix, pooling)\n","\n","      top_k_recommended_course = self.get_top_k(cosine_max_aggregate, group_course_row['somonhoc'])\n","      recommended_result = recommended_result + [\n","          {\n","              'nhomloaimh': group_course_row['nhomloaimh'],\n","              'mamh': index,\n","              'score': value\n","          }\n","          for index, value in top_k_recommended_course.items()\n","      ]\n","    return pd.DataFrame(recommended_result)\n","\n","  def evaluate(self, mssv: str, term: int, pooling='max') -> pd.DataFrame:\n","    recommended_courses = self.recommend(mssv, term, pooling)\n","    if len(recommended_courses) == 0:\n","      return 0, 0, 0\n","    recommended_courses = recommended_courses['mamh']\n","    actual_courses = self.score[(self.score['mssv'] == mssv) & (self.score['sohocky'] == term)]['mamh'].unique()\n","\n","    true_positive_count = recommended_courses.isin(actual_courses).sum()\n","    precision = true_positive_count / len(recommended_courses) if len(recommended_courses) > 0 else 0\n","    recall = true_positive_count / len(actual_courses) if len(actual_courses) > 0 else 0\n","    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n","\n","    return precision, recall, f1_score"],"metadata":{"id":"cIPMRi9alf7w","executionInfo":{"status":"ok","timestamp":1733471195261,"user_tz":-420,"elapsed":5,"user":{"displayName":"0390_ Phan Thanh Hải","userId":"13609693981152396951"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["import random\n","from tqdm import tqdm\n","\n","# random.seed(42)\n","# Lọc các sinh viên bắt đầu học năm 2014\n","student_2014 = processed_student[processed_student['namhoc_batdau'] == 2014]['mssv'].unique()\n","\n","terms = [2, 3, 4, 5]\n","filtered_scores = processed_score[processed_score['sohocky'].isin(terms) & processed_score['mssv'].isin(student_2014)]\n","\n","student_with_all_terms = filtered_scores.groupby('mssv').filter(lambda x: set(x['sohocky']) == set(terms))['mssv'].unique()\n","\n","student_with_all_terms = list(student_with_all_terms)\n","\n","\n","qualified_students = list(set(student_2014) & set(student_with_all_terms))\n","# selected_students = random.sample(qualified_students, 100)\n","\n","pooling_list = ['max', 'min', 'sum', 'mean']\n","gridsearch_results = []\n","for pooling in tqdm(pooling_list):\n","  evaluation_results = []\n","  for i in range(2, 6):\n","    for mssv in qualified_students:\n","        pipeline = Baseline3(group_course, processed_student, processed_score, processed_course, onehot_course, PhoBERT_paraphased_tomtat)\n","        precision, recall, f1_score = pipeline.evaluate(mssv, i, pooling)\n","        evaluation_results.append({\n","            'mssv': mssv,\n","            'term': i,\n","            'precision': precision,\n","            'recall': recall,\n","            'f1_score': f1_score\n","        })\n","\n","  evaluation_df = pd.DataFrame(evaluation_results)\n","  mean_precision_by_term = evaluation_df.groupby('term')['precision'].mean()\n","  mean_precision = evaluation_df['precision'].mean()\n","  mean_recall_by_term = evaluation_df.groupby('term')['recall'].mean()\n","  mean_recall = evaluation_df['recall'].mean()\n","  mean_f1_score_by_term = evaluation_df.groupby('term')['f1_score'].mean()\n","  mean_f1_score = evaluation_df['f1_score'].mean()\n","  gridsearch_results.append({\n","      'pooling': pooling,\n","      'mean_precision': mean_precision,\n","      'mean_recall': mean_recall,\n","      'mean_f1_score': mean_f1_score\n","  })\n","gridsearch_df = pd.DataFrame(gridsearch_results)\n","gridsearch_df.to_excel('/content/drive/MyDrive/Nhóm 5 - DS317.P11/Đồ án mô học/Gridsearch Finetune/Finetune With Raw Data/Baseline 3/gridsearch_results (full).xlsx')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KHv-wft3xqdg","outputId":"94d0b249-5d14-40df-c04a-e4346c5e44a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":[" 75%|███████▌  | 3/4 [17:55<05:58, 358.13s/it]"]}]}]}